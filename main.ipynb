{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:48.058796Z",
     "start_time": "2025-12-19T16:33:26.787006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "from sympy.parsing.sympy_parser import transformations\n",
    "\n",
    "sys.path.append('./packages')\n",
    "sys.path.append('./wrappers')\n",
    "from dataset_wrapper import initialise_dataset"
   ],
   "id": "c8110a0aec4151a3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:48.105902Z",
     "start_time": "2025-12-19T16:33:48.080776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import PersistentDataset\n",
    "from monai.metrics import DiceMetric\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:48.137645Z",
     "start_time": "2025-12-19T16:33:48.105902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify to suit local machine\n",
    "data_path = '../data/'"
   ],
   "id": "56e4f28e82a62149",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:48.167445Z",
     "start_time": "2025-12-19T16:33:48.150439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DO NOT TOUCH\n",
    "# Select what datatypes you would like to load from the dataset\n",
    "# flair: Fluid-Attenuated Inversion Recovery. Highlights edema (swelling around tumor)\n",
    "# t1: Standard T1-weighted scan. Good anatomical detail\n",
    "# t1ce: T1-weighted with contrast enhancement. Shows areas where tumor enhances after injection of gadolinium\n",
    "# t2: T2-weighted scan. Bright scan for fluids\n",
    "\n",
    "modalities = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "\n",
    "mod_dic = {}\n",
    "for index, modality in enumerate(modalities):\n",
    "    mod_dic[modality] = index"
   ],
   "id": "987c6ba55061f9c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:49.632242Z",
     "start_time": "2025-12-19T16:33:49.036647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This line should only every be ADDED to, and NOT subtracted from\n",
    "# Import more functions if needed. Add them to transformations to apply them to data\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    ToTensord,\n",
    "    AdjustContrastd,\n",
    "    HistogramNormalized,\n",
    "    NormalizeIntensityd,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CenterSpatialCropd,\n",
    "    SpatialPadd,\n",
    ")\n",
    "\n",
    "from wrapped_transformations import N4BiasFieldCorrectionCustomd"
   ],
   "id": "3e29aade11806436",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wrapped_transformations.N4BiasFieldCorrectionCustomd at 0x266b983d8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:49.757782Z",
     "start_time": "2025-12-19T16:33:49.715251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre-processing. Add as many pre-processing transformations as you wish. Must be from monai\n",
    "# IMPORTANT: Do not remove transformations outside the \"Personal Transformations\" section\n",
    "deterministic_transformations = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"seg_mask\"]),  # loads NIfTI files\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    EnsureChannelFirstd(keys=\"seg_mask\"),\n",
    "    EnsureTyped(keys=\"seg_mask\", dtype=np.uint8),\n",
    "\n",
    "# ----------------- Personal Transformations ----------------- #\n",
    "\n",
    "    Orientationd(keys=[\"image\", \"seg_mask\"], axcodes=\"RAS\"),\n",
    "    Spacingd(\n",
    "        keys=[\"image\", \"seg_mask\"],\n",
    "        pixdim=(1.0, 1.0, 1.0),\n",
    "        mode=(\"bilinear\", \"nearest\")\n",
    "    ),\n",
    "    N4BiasFieldCorrectionCustomd(keys=[\"image\"]),\n",
    "    CenterSpatialCropd(keys=[\"image\", \"seg_mask\"], roi_size=(160, 192, 160)),\n",
    "    SpatialPadd(keys=[\"image\",\"seg_mask\"], spatial_size=(160,192,160)),  # pad to multiples of 16\n",
    "    ScaleIntensityRanged(\n",
    "        keys=[\"image\"],\n",
    "        a_min=-1000, a_max=3000,\n",
    "        b_min=0.0, b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    HistogramNormalized(keys=[\"image\"], num_bins=256),\n",
    "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
    "    AdjustContrastd(keys=[\"image\"], gamma=1.2),\n",
    "\n",
    "# ------------------------------------------------------------ #\n",
    "\n",
    "    ToTensord(keys=[\"image\", \"seg_mask\"])  # convert both to torch tensors\n",
    "])"
   ],
   "id": "fb9c1e5e12fc919d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vodou\\miniconda3\\envs\\tumorsegmentation\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:49.853313Z",
     "start_time": "2025-12-19T16:33:49.842309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformations to use when augmenting training dataset\n",
    "from monai.transforms import (\n",
    "    RandFlipd,\n",
    "    RandAffined,\n",
    "    Rand3DElasticd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd\n",
    ")"
   ],
   "id": "d483d53417dc6fce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:49.962835Z",
     "start_time": "2025-12-19T16:33:49.904309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Edit to change which transformations are used when augmenting training dataset\n",
    "augmentation_transformations = Compose([\n",
    "\n",
    "    # ---------------- Spatial (image + mask) ---------------- #\n",
    "\n",
    "    # Left-right flip (safe for brain)\n",
    "    RandFlipd(\n",
    "        keys=[\"image\", \"seg_mask\"],\n",
    "        spatial_axis=0,\n",
    "        prob=0.5\n",
    "    ),\n",
    "\n",
    "    # Small rotations, translations, and scaling\n",
    "    RandAffined(\n",
    "        keys=[\"image\", \"seg_mask\"],\n",
    "        prob=0.3,\n",
    "        rotate_range=(0.1, 0.1, 0.1),     # ~±6°\n",
    "        translate_range=(5, 5, 5),        # voxels\n",
    "        scale_range=(0.1, 0.1, 0.1),\n",
    "        mode=(\"bilinear\", \"nearest\"),\n",
    "        padding_mode=\"border\"\n",
    "    ),\n",
    "\n",
    "    # Mild elastic deformation (simulates anatomy variance)\n",
    "    Rand3DElasticd(\n",
    "        keys=[\"image\", \"seg_mask\"],\n",
    "        prob=0.15,\n",
    "        sigma_range=(5, 8),\n",
    "        magnitude_range=(50, 100),\n",
    "        mode=(\"bilinear\", \"nearest\"),\n",
    "        padding_mode=\"border\"\n",
    "    ),\n",
    "\n",
    "    # ---------------- Intensity (image only) ---------------- #\n",
    "\n",
    "    # Scanner noise\n",
    "    RandGaussianNoised(\n",
    "        keys=[\"image\"],\n",
    "        prob=0.2,\n",
    "        mean=0.0,\n",
    "        std=0.01\n",
    "    ),\n",
    "\n",
    "    # Slight smoothing (resolution variation)\n",
    "    RandGaussianSmoothd(\n",
    "        keys=[\"image\"],\n",
    "        prob=0.2,\n",
    "        sigma_x=(0.5, 1.0),\n",
    "        sigma_y=(0.5, 1.0),\n",
    "        sigma_z=(0.5, 1.0)\n",
    "    ),\n",
    "\n",
    "    # Intensity scaling\n",
    "    RandScaleIntensityd(\n",
    "        keys=[\"image\"],\n",
    "        factors=0.1,\n",
    "        prob=0.3\n",
    "    ),\n",
    "\n",
    "    # Intensity shift\n",
    "    RandShiftIntensityd(\n",
    "        keys=[\"image\"],\n",
    "        offsets=0.1,\n",
    "        prob=0.3\n",
    "    ),\n",
    "])"
   ],
   "id": "1c558921d23c88e1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:53.455303Z",
     "start_time": "2025-12-19T16:33:49.994834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialises base dataset that you can operate on\n",
    "# Loads data DYNAMICALLY\n",
    "dataset_access = initialise_dataset(data_path, modalities=modalities, transformations=deterministic_transformations)\n",
    "base_dataset = PersistentDataset(\n",
    "    data=dataset_access.files,\n",
    "    transform=dataset_access.transform,\n",
    "    cache_dir=\"./cache\"\n",
    ")"
   ],
   "id": "76a045ca87d44e25",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:33:53.519316Z",
     "start_time": "2025-12-19T16:33:53.507318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialises the augmented, training dataset\n",
    "train_dataset = Dataset(\n",
    "    data=base_dataset,\n",
    "    transform=augmentation_transformations\n",
    ")"
   ],
   "id": "3b3e62a42aa831d5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T19:15:05.959311Z",
     "start_time": "2025-12-19T19:15:05.906797Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)",
   "id": "4dad472ae13879ee",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T19:15:07.417547Z",
     "start_time": "2025-12-19T19:15:07.297012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_determinism(seed=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "8b89267990e03039",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T19:15:09.243370Z",
     "start_time": "2025-12-19T19:15:08.440241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We will be comparing our 2d network to monai's 3d network (?)\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=4,       # MRI modalities\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ],
   "id": "43e0de3843effaf9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T19:15:09.290364Z",
     "start_time": "2025-12-19T19:15:09.258367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = DiceLoss(to_onehot_y=False, softmax=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "2f01dbea7f00c679",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-19T19:15:11.141636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 50\n",
    "\n",
    "img_idx = 0\n",
    "mask_idx = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_data in train_loader:\n",
    "        \n",
    "        inputs = batch_data[\"image\"].to(device)\n",
    "        labels = batch_data[\"seg_mask\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)   # logits\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ],
   "id": "1e319b0123bfb4fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vodou\\miniconda3\\envs\\tumorsegmentation\\lib\\site-packages\\monai\\losses\\dice.py:160: UserWarning: single channel prediction, `softmax=True` ignored.\n",
      "  warnings.warn(\"single channel prediction, `softmax=True` ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n",
      "Inputs acquired\n",
      "Labels acquired\n",
      "Optimiser zeroed\n",
      "Outputs calculated\n",
      "Loss calculated\n",
      "Loss backpropagated\n",
      "Grad. Descent done\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"monai_3d_unet.pt\")",
   "id": "ccbe7840002dcbb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "99115cf4e5b41732"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
